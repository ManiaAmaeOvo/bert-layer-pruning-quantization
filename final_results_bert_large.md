| Model                                       |   Size (MB) |   Accuracy (GPU) |   Latency (GPU, ms) |   Peak GPU Mem (MB) | Accuracy (CPU)   | Latency (CPU, ms)   |
|:--------------------------------------------|------------:|-----------------:|--------------------:|--------------------:|:-----------------|:--------------------|
| 1. Baseline (bert-large, 24L, FP32)         |     3836.7  |           0.9312 |                6    |             1288.91 | 0.9312           | 383.98              |
| 2. Pruned (bert-large, 16L, FP32)           |      895    |           0.9392 |                4.14 |              904.51 | 0.9392           | 288.00              |
| 3. Pruned+Quantized (bert-large, 16L, FP16) |      447.97 |           0.9392 |                4.17 |              456.82 | N/A              | N/A                 |